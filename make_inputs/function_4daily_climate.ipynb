{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load, concatenate and calculate Max Daily Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "from iris.util import unify_time_units\n",
    "from iris.experimental.equalise_cubes import equalise_attributes\n",
    "import iris.quickplot as qplt\n",
    "# import pandas as pd\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from libs.plot_maps import *\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "%matplotlib inline\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "path_in  = '../data/'\n",
    "path_out = '../outputs/climate/from_2001/'\n",
    "\n",
    "\n",
    "# Set year range\n",
    "years = range(2001, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as browser\n",
    "def format_climate(years, path, path_out, outfile, cal_wind=False, file_name='temp_4_daily/air.sig995.',\n",
    "                   dlySumFun = iris.analysis.MAX, mnthSumFun = iris.analysis.MEAN):\n",
    "    '''Function to condense multiple years of x4 daily measurements into maximum daily, monthly-averages.\n",
    "    Produces one netcdf file at the end.\n",
    "    \n",
    "    Variables are:\n",
    "    + years = the year ranges you want to condense e.g range(2000, 2002) will be 2000, 2001\n",
    "    \n",
    "    + path = directory with *all* data\n",
    "    \n",
    "    + path_out = the exit directory where you want the data saved\n",
    "    \n",
    "    + outfile = the output file name. The year range and .nc will be added at the end of this\n",
    "    \n",
    "    + cal_wind = Boolean argument\n",
    "                If True, the function will assume you're directing it to path with both v and u files.\n",
    "                It will calculate total wind, s, as described in `cal_wnd_spd.ipynb`.\n",
    "                \n",
    "                If False, the function will load temperature data and only calcualte max daily, monthly averages.\n",
    "    \n",
    "    + file_name = a string with the main section of the file name. e.g. for 'air.2m.gauss.2011.nc', this would be\n",
    "                'air.2m.gauss.' You don't need this if you are calculating wind speed as the file names are already\n",
    "                in the function :)'''\n",
    "\n",
    "    if cal_wind:\n",
    "        u_files = []\n",
    "        v_files = []\n",
    "        for year in years:\n",
    "            u_files.append(path_in + 'u_wind/uwnd.sig995.' + str(year) + '.nc')\n",
    "            v_files.append(path_in + 'v_wind/vwnd.sig995.' + str(year) + '.nc')\n",
    "\n",
    "        uList = []\n",
    "        vList = []\n",
    "\n",
    "        # Loading in files\n",
    "        print('Loading in u files...')\n",
    "        for i in u_files:\n",
    "            dfu = iris.load_cube(i)\n",
    "            dfu.coord('time').attributes = {}\n",
    "            uList.append(dfu)\n",
    "        print('Files loaded')\n",
    "\n",
    "        print('Loading in v files...')\n",
    "        for j in v_files:\n",
    "            dfv = iris.load_cube(j)            \n",
    "            dfv.coord('time').attributes = {}\n",
    "            vList.append(dfv)\n",
    "        print('Files loaded')\n",
    "\n",
    "        ### For all u and v files\n",
    "        # u_files = glob.glob(path + 'u*.nc') # use 'recursive = True' to include subdirectories\n",
    "        # u_files = sorted(u_files) # sort alphabetically\n",
    "        # v_files = glob.glob(path + 'v*.nc') \n",
    "\n",
    "        u_cube_list = iris.cube.CubeList(uList)\n",
    "        v_cube_list = iris.cube.CubeList(vList)\n",
    "        slist = v_cube_list.copy()\n",
    "        \n",
    "        equalise_attributes(u_cube_list)\n",
    "        unify_time_units(u_cube_list)\n",
    "\n",
    "        equalise_attributes(v_cube_list)\n",
    "        unify_time_units(v_cube_list)\n",
    "\n",
    "        print('Calculating wind speed... (this may take a while)')\n",
    "        for year in range(len(years)):\n",
    "            v_dat = v_cube_list[year].data\n",
    "            u_dat = u_cube_list[year].data\n",
    "            s_dat = np.sqrt((v_dat * v_dat) + (u_dat * u_dat))\n",
    "\n",
    "            slist[year].data = s_dat\n",
    "        print('Wind speed calculated')\n",
    "        t_cube_list = iris.cube.CubeList(slist)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        t_files = []\n",
    "        for year in years:\n",
    "            t_files.append(path + file_name + str(year) + '.nc')\n",
    "\n",
    "        tList = []\n",
    "        print('Loading in files...')\n",
    "        for i in t_files:\n",
    "            df = iris.load_cube(i)\n",
    "            df.coord('time').attributes = {}\n",
    "            tList.append(df)\n",
    "        print('Files loaded')\n",
    "\n",
    "        # Turn into cube list\n",
    "        t_cube_list = iris.cube.CubeList(tList)\n",
    "\n",
    "        # So all units match up\n",
    "        equalise_attributes(t_cube_list)\n",
    "        unify_time_units(t_cube_list)\n",
    "\n",
    "    # Concatenate cubes together (end of if loop)\n",
    "    print('Concatenating...')\n",
    "    t = t_cube_list.concatenate_cube()\n",
    "    print('Concatenating complete')\n",
    "    \n",
    "    # Add coordinates in\n",
    "    print('Adding coordinates...')\n",
    "    try:\n",
    "        iris.coord_categorisation.add_month(t, 'time', name='month')\n",
    "        iris.coord_categorisation.add_day_of_year(t, 'time', name='day_of_year')\n",
    "        iris.coord_categorisation.add_year(t, 'time', name='year')\n",
    "        print('Success')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Max daily values\n",
    "    print('Aggregating...')\n",
    "    test = t.aggregated_by(['day_of_year', 'year'], dlySumFun)\n",
    "    swnd = test.aggregated_by(['month', 'year'], mnthSumFun)\n",
    "    print('Aggregation complete')\n",
    "    \n",
    "    # Saving outputs\n",
    "    print('Saving files...')\n",
    "    out = path_out + outfile + str(years[0]) + '-' + str(years[len(years) -1]) + '.nc'\n",
    "    print(out)\n",
    "    iris.save(swnd, out)\n",
    "    print('Save complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in files...\n",
      "Files loaded\n",
      "Concatenating...\n",
      "Concatenating complete\n",
      "Adding coordinates...\n",
      "Success\n",
      "Aggregating...\n",
      "Aggregation complete\n",
      "Saving files...\n",
      "../outputs/climate/from_2001/rhumMax.2001-2019.nc\n",
      "Save complete.\n",
      "Loading in files...\n",
      "Files loaded\n",
      "Concatenating...\n",
      "Concatenating complete\n",
      "Adding coordinates...\n",
      "Success\n",
      "Aggregating...\n",
      "Aggregation complete\n",
      "Saving files...\n",
      "../outputs/climate/from_2001/rhumMaxMax.2001-2019.nc\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "## ## making Tmax file\n",
    "format_climate(cal_wind=False, years=years, path=path_in, path_out=path_out, outfile='rhumMax.', file_name='rh_4_daily/rhum.sig995.', \n",
    "               dlySumFun = iris.analysis.MIN, mnthSumFun = iris.analysis.MIN)\n",
    "format_climate(cal_wind=False, years=years, path=path_in, path_out=path_out, outfile='rhumMaxMax.', file_name='rh_4_daily/rhum.sig995.', \n",
    "               mnthSumFun = iris.analysis.MIN)\n",
    "\n",
    "\n",
    "## making Tmax file\n",
    "#format_climate(cal_wind=False, years=years, path=path_in, path_out=path_out, outfile='tmax.')\n",
    "#format_climate(cal_wind=False, years=years, path=path_in, path_out=path_out, outfile='tmaxMax.', mnthSumFun = iris.analysis.MAX)\n",
    "\n",
    "##making Smax file\n",
    "#format_climate(cal_wind=True, years=years, path=path_in, path_out=path_out, outfile='swnd.')\n",
    "#format_climate(cal_wind=True, years=years, path=path_in, path_out=path_out, outfile='swndMax.', mnthSumFun = iris.analysis.MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
